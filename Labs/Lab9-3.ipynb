{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bj_hmm8ACsbD"
   },
   "source": [
    "### LAB<sup>9-3</sup> 성능 좋은 CNN을 가져다 써보자 (p.342)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wmZuHX9nCzB2"
   },
   "source": [
    "**실습 목표**\n",
    "\n",
    "텐서플로우는 이미 많은 학자들과 개발자들이 개발하여 검증한 훌륭한 CNN 모델을 제공하고 있다. 우리는 구글사에서 만든 inception V3라는 뛰어난 모델을 사용하여 MNIST 데이터의 분류를 할 것이다. 결과는 99%의 매우 높은 정확도를 보일 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M3fiVucqDCUY"
   },
   "source": [
    "#### 1. 텐서플로우와 맷플롯립, 넘파이, skimage등 관련 패키지를 임포트한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BpdekmPvCqT8"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage.transform import resize\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras import models, layers\n",
    "from keras.models import Model, load_model\n",
    "import pandas as pd\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SnWlA4_yDHMd"
   },
   "source": [
    "#### 2. MNIST 데이터 셋을 읽고 학습용 데이터와 테스트용 데이터로 나누도록 하자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N5ByKKCiDMQC"
   },
   "source": [
    "8장에서 살펴본 바와 같이 학습에 사용할 데이터는 x_train이며, 이 데이터의 레이블이 y_train이다. 또한 테스트용 데이터 역시 데이터와 레이블로 이루어져 있다. 이 데이터들을 255로 나누어서 학습에 용이한 0에서 1 사이의 값으로 정규화시키는 것 역시 8장의 내용과 동일하다. 데이터가 너무 많아 빠른 실습을 위해 훈련 데이터는 10,000개, 검증 데이터는 2,000개만 사용해 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4NBZ-m2ADL3b",
    "outputId": "f03298ed-c084-4218-8e33-45bf865755c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n",
      "11501568/11490434 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "# 훈련 데이터는 10000개, 검증 데이터는 2000개만 사용\n",
    "x_train, x_test = x_train[:10000] / 255.0, x_test[:2000] / 255.0\n",
    "y_train, y_test = y_train[:10000], y_test[:2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JXgHha9kDdep"
   },
   "source": [
    "#### 3. MNIST 데이터 셋의 이미지는 28x28 크기의 비교적 작은 이미지이다. 하지만 inception V3의 최소 입력 크기는 75x75 크기의 이미지이므로 x_train과 x_test의 모든 이미지 집합을 75x75 크기의 이미지로 변환시키는 전처리 과정이 필요하다. 또한 numpy의 dstack을 사용해서 빨강, 녹색, 파랑 채널을 동일한 색으로 지정하도록 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3H5a3WwqDxjz",
    "outputId": "f8a12bb3-825d-4f53-c613-28f0b7c176ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 75, 75, 3)\n"
     ]
    }
   ],
   "source": [
    "x_train_preprocess = np.zeros((x_train.shape[0], 75, 75, 3), dtype=np.float32)\n",
    "\n",
    "print(x_train_preprocess.shape)\n",
    "# 훈련 데이터 각각의 크기를 75x75로 변형 (인셉션 모델 최소 입력 크기)\n",
    "for i, img in enumerate(x_train):\n",
    "    img_resize = resize(img, (75, 75), anti_aliasing=True)\n",
    "    x_train_preprocess[i] = np.dstack([img_resize, img_resize, img_resize])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3FYeVW8FDx7x"
   },
   "source": [
    "#### 4. 테스트 데이터에도 같은 작업을 진행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0BdE_dfFD0qd",
    "outputId": "adae74b9-c3d4-444d-8906-76f63ed1aa5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 75, 75, 3)\n"
     ]
    }
   ],
   "source": [
    "x_test_preprocess = np.zeros((x_test.shape[0], 75, 75, 3), dtype=np.float32)\n",
    "\n",
    "print(x_test_preprocess.shape)\n",
    "# 훈련 데이터 각각의 크기를 75x75로 변형 (인셉션 모델 최소 입력 크기)\n",
    "for i, img in enumerate(x_test):\n",
    "    img_resize = resize(img, (75, 75), anti_aliasing=True)\n",
    "    x_test_preprocess[i] = np.dstack([img_resize, img_resize, img_resize])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FvDr5SeKD1DM"
   },
   "source": [
    "#### 5. 이제 다음과 같이 사전학습된 InceptionV3 모델을 가져오도록 하자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YQqDNaxfD6OE"
   },
   "source": [
    "이 모델의 입력은 (75, 75, 3)의 크기를 가지는 이미지 데이터가 될 것이다. include_top은 네트워크의 마지막 계층으로 맨 위에 완전 연결 계층을 포함할지 여부를 나타내는 bool값이며 이미 검증된 가중치를 사용할 경우 weights = 'imagenet'과 같은 가중치 값을 지정할 수 있다. 여기서는 None을 지정하여 임의의 난수값으로 가중치를 초기화한다. 생성된 모델의 정보를 summary()를 이용하여 살펴보면 이 모델에 사용된 많은 합성곱, 풀링층에 대한 정보를 볼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6la2M-6cD5nE",
    "outputId": "bfd91512-66ac-49c6-889f-adfd9e4bad55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inception_v3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 75, 75, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 37, 37, 32)   864         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 37, 37, 32)  96          ['conv2d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 37, 37, 32)   0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 35, 35, 32)   9216        ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 35, 35, 32)  96          ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 35, 35, 32)   0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 35, 35, 64)   18432       ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 35, 35, 64)  192         ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 35, 35, 64)   0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 17, 17, 64)   0           ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 17, 17, 80)   5120        ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 17, 17, 80)  240         ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 17, 17, 80)   0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 15, 15, 192)  138240      ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 15, 15, 192)  576        ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 15, 15, 192)  0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 7, 7, 192)   0           ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 7, 7, 64)     12288       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 7, 7, 64)    192         ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 7, 7, 64)     0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 7, 7, 48)     9216        ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 7, 7, 96)     55296       ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 7, 7, 48)    144         ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 7, 7, 96)    288         ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 7, 7, 48)     0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 7, 7, 96)     0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " average_pooling2d (AveragePool  (None, 7, 7, 192)   0           ['max_pooling2d_1[0][0]']        \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 7, 7, 64)     12288       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 7, 7, 64)     76800       ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 7, 7, 96)     82944       ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 7, 7, 32)     6144        ['average_pooling2d[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 7, 7, 64)    192         ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 7, 7, 64)    192         ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 7, 7, 96)    288         ['conv2d_10[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 7, 7, 32)    96          ['conv2d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 7, 7, 64)     0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 7, 7, 64)     0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 7, 7, 96)     0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 7, 7, 32)     0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " mixed0 (Concatenate)           (None, 7, 7, 256)    0           ['activation_5[0][0]',           \n",
      "                                                                  'activation_7[0][0]',           \n",
      "                                                                  'activation_10[0][0]',          \n",
      "                                                                  'activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 7, 7, 64)     16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 7, 7, 64)    192         ['conv2d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 7, 7, 64)     0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 7, 7, 48)     12288       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 7, 7, 96)     55296       ['activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 7, 7, 48)    144         ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 7, 7, 96)    288         ['conv2d_16[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 7, 7, 48)     0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 7, 7, 96)     0           ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_1 (AveragePo  (None, 7, 7, 256)   0           ['mixed0[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 7, 7, 64)     16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 7, 7, 64)     76800       ['activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 7, 7, 96)     82944       ['activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 7, 7, 64)     16384       ['average_pooling2d_1[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 7, 7, 64)    192         ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 7, 7, 64)    192         ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 7, 7, 96)    288         ['conv2d_17[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 7, 7, 64)    192         ['conv2d_18[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 7, 7, 64)     0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 7, 7, 64)     0           ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 7, 7, 96)     0           ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 7, 7, 64)     0           ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " mixed1 (Concatenate)           (None, 7, 7, 288)    0           ['activation_12[0][0]',          \n",
      "                                                                  'activation_14[0][0]',          \n",
      "                                                                  'activation_17[0][0]',          \n",
      "                                                                  'activation_18[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 7, 7, 64)     18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 7, 7, 64)    192         ['conv2d_22[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_22 (Activation)     (None, 7, 7, 64)     0           ['batch_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 7, 7, 48)     13824       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 7, 7, 96)     55296       ['activation_22[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 7, 7, 48)    144         ['conv2d_20[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 7, 7, 96)    288         ['conv2d_23[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 7, 7, 48)     0           ['batch_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, 7, 7, 96)     0           ['batch_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_2 (AveragePo  (None, 7, 7, 288)   0           ['mixed1[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 7, 7, 64)     18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 7, 7, 64)     76800       ['activation_20[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 7, 7, 96)     82944       ['activation_23[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 7, 7, 64)     18432       ['average_pooling2d_2[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 7, 7, 64)    192         ['conv2d_19[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 7, 7, 64)    192         ['conv2d_21[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 7, 7, 96)    288         ['conv2d_24[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 7, 7, 64)    192         ['conv2d_25[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 7, 7, 64)     0           ['batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 7, 7, 64)     0           ['batch_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, 7, 7, 96)     0           ['batch_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 7, 7, 64)     0           ['batch_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " mixed2 (Concatenate)           (None, 7, 7, 288)    0           ['activation_19[0][0]',          \n",
      "                                                                  'activation_21[0][0]',          \n",
      "                                                                  'activation_24[0][0]',          \n",
      "                                                                  'activation_25[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 7, 7, 64)     18432       ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 7, 7, 64)    192         ['conv2d_27[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, 7, 7, 64)     0           ['batch_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 7, 7, 96)     55296       ['activation_27[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 7, 7, 96)    288         ['conv2d_28[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_28 (Activation)     (None, 7, 7, 96)     0           ['batch_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 3, 3, 384)    995328      ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 3, 3, 96)     82944       ['activation_28[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_26[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 3, 3, 96)    288         ['conv2d_29[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " activation_29 (Activation)     (None, 3, 3, 96)     0           ['batch_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 3, 3, 288)   0           ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " mixed3 (Concatenate)           (None, 3, 3, 768)    0           ['activation_26[0][0]',          \n",
      "                                                                  'activation_29[0][0]',          \n",
      "                                                                  'max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 3, 3, 128)    98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, 3, 3, 128)   384         ['conv2d_34[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_34 (Activation)     (None, 3, 3, 128)    0           ['batch_normalization_34[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 3, 3, 128)    114688      ['activation_34[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, 3, 3, 128)   384         ['conv2d_35[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_35 (Activation)     (None, 3, 3, 128)    0           ['batch_normalization_35[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 3, 3, 128)    98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 3, 3, 128)    114688      ['activation_35[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 3, 3, 128)   384         ['conv2d_31[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 3, 3, 128)   384         ['conv2d_36[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_31 (Activation)     (None, 3, 3, 128)    0           ['batch_normalization_31[0][0]'] \n",
      "                                                                                                  \n",
      " activation_36 (Activation)     (None, 3, 3, 128)    0           ['batch_normalization_36[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 3, 3, 128)    114688      ['activation_31[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 3, 3, 128)    114688      ['activation_36[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 3, 3, 128)   384         ['conv2d_32[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 3, 3, 128)   384         ['conv2d_37[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_32 (Activation)     (None, 3, 3, 128)    0           ['batch_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " activation_37 (Activation)     (None, 3, 3, 128)    0           ['batch_normalization_37[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_3 (AveragePo  (None, 3, 3, 768)   0           ['mixed3[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 3, 3, 192)    147456      ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 3, 3, 192)    172032      ['activation_32[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 3, 3, 192)    172032      ['activation_37[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, 3, 3, 192)    147456      ['average_pooling2d_3[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 3, 3, 192)   576         ['conv2d_30[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 3, 3, 192)   576         ['conv2d_33[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 3, 3, 192)   576         ['conv2d_38[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 3, 3, 192)   576         ['conv2d_39[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_30 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_30[0][0]'] \n",
      "                                                                                                  \n",
      " activation_33 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_33[0][0]'] \n",
      "                                                                                                  \n",
      " activation_38 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_38[0][0]'] \n",
      "                                                                                                  \n",
      " activation_39 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_39[0][0]'] \n",
      "                                                                                                  \n",
      " mixed4 (Concatenate)           (None, 3, 3, 768)    0           ['activation_30[0][0]',          \n",
      "                                                                  'activation_33[0][0]',          \n",
      "                                                                  'activation_38[0][0]',          \n",
      "                                                                  'activation_39[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)             (None, 3, 3, 160)    122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_44 (BatchN  (None, 3, 3, 160)   480         ['conv2d_44[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_44 (Activation)     (None, 3, 3, 160)    0           ['batch_normalization_44[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)             (None, 3, 3, 160)    179200      ['activation_44[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_45 (BatchN  (None, 3, 3, 160)   480         ['conv2d_45[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_45 (Activation)     (None, 3, 3, 160)    0           ['batch_normalization_45[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)             (None, 3, 3, 160)    122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)             (None, 3, 3, 160)    179200      ['activation_45[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, 3, 3, 160)   480         ['conv2d_41[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_46 (BatchN  (None, 3, 3, 160)   480         ['conv2d_46[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_41 (Activation)     (None, 3, 3, 160)    0           ['batch_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " activation_46 (Activation)     (None, 3, 3, 160)    0           ['batch_normalization_46[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)             (None, 3, 3, 160)    179200      ['activation_41[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)             (None, 3, 3, 160)    179200      ['activation_46[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_42 (BatchN  (None, 3, 3, 160)   480         ['conv2d_42[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_47 (BatchN  (None, 3, 3, 160)   480         ['conv2d_47[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_42 (Activation)     (None, 3, 3, 160)    0           ['batch_normalization_42[0][0]'] \n",
      "                                                                                                  \n",
      " activation_47 (Activation)     (None, 3, 3, 160)    0           ['batch_normalization_47[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_4 (AveragePo  (None, 3, 3, 768)   0           ['mixed4[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)             (None, 3, 3, 192)    147456      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)             (None, 3, 3, 192)    215040      ['activation_42[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_48 (Conv2D)             (None, 3, 3, 192)    215040      ['activation_47[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_49 (Conv2D)             (None, 3, 3, 192)    147456      ['average_pooling2d_4[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 3, 3, 192)   576         ['conv2d_40[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_43 (BatchN  (None, 3, 3, 192)   576         ['conv2d_43[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_48 (BatchN  (None, 3, 3, 192)   576         ['conv2d_48[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_49 (BatchN  (None, 3, 3, 192)   576         ['conv2d_49[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_40 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_40[0][0]'] \n",
      "                                                                                                  \n",
      " activation_43 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_43[0][0]'] \n",
      "                                                                                                  \n",
      " activation_48 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_48[0][0]'] \n",
      "                                                                                                  \n",
      " activation_49 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_49[0][0]'] \n",
      "                                                                                                  \n",
      " mixed5 (Concatenate)           (None, 3, 3, 768)    0           ['activation_40[0][0]',          \n",
      "                                                                  'activation_43[0][0]',          \n",
      "                                                                  'activation_48[0][0]',          \n",
      "                                                                  'activation_49[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_54 (Conv2D)             (None, 3, 3, 160)    122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_54 (BatchN  (None, 3, 3, 160)   480         ['conv2d_54[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_54 (Activation)     (None, 3, 3, 160)    0           ['batch_normalization_54[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_55 (Conv2D)             (None, 3, 3, 160)    179200      ['activation_54[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_55 (BatchN  (None, 3, 3, 160)   480         ['conv2d_55[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_55 (Activation)     (None, 3, 3, 160)    0           ['batch_normalization_55[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_51 (Conv2D)             (None, 3, 3, 160)    122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_56 (Conv2D)             (None, 3, 3, 160)    179200      ['activation_55[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_51 (BatchN  (None, 3, 3, 160)   480         ['conv2d_51[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_56 (BatchN  (None, 3, 3, 160)   480         ['conv2d_56[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_51 (Activation)     (None, 3, 3, 160)    0           ['batch_normalization_51[0][0]'] \n",
      "                                                                                                  \n",
      " activation_56 (Activation)     (None, 3, 3, 160)    0           ['batch_normalization_56[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_52 (Conv2D)             (None, 3, 3, 160)    179200      ['activation_51[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_57 (Conv2D)             (None, 3, 3, 160)    179200      ['activation_56[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_52 (BatchN  (None, 3, 3, 160)   480         ['conv2d_52[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_57 (BatchN  (None, 3, 3, 160)   480         ['conv2d_57[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_52 (Activation)     (None, 3, 3, 160)    0           ['batch_normalization_52[0][0]'] \n",
      "                                                                                                  \n",
      " activation_57 (Activation)     (None, 3, 3, 160)    0           ['batch_normalization_57[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_5 (AveragePo  (None, 3, 3, 768)   0           ['mixed5[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_50 (Conv2D)             (None, 3, 3, 192)    147456      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_53 (Conv2D)             (None, 3, 3, 192)    215040      ['activation_52[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_58 (Conv2D)             (None, 3, 3, 192)    215040      ['activation_57[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_59 (Conv2D)             (None, 3, 3, 192)    147456      ['average_pooling2d_5[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_50 (BatchN  (None, 3, 3, 192)   576         ['conv2d_50[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_53 (BatchN  (None, 3, 3, 192)   576         ['conv2d_53[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_58 (BatchN  (None, 3, 3, 192)   576         ['conv2d_58[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_59 (BatchN  (None, 3, 3, 192)   576         ['conv2d_59[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_50 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_50[0][0]'] \n",
      "                                                                                                  \n",
      " activation_53 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_53[0][0]'] \n",
      "                                                                                                  \n",
      " activation_58 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_58[0][0]'] \n",
      "                                                                                                  \n",
      " activation_59 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_59[0][0]'] \n",
      "                                                                                                  \n",
      " mixed6 (Concatenate)           (None, 3, 3, 768)    0           ['activation_50[0][0]',          \n",
      "                                                                  'activation_53[0][0]',          \n",
      "                                                                  'activation_58[0][0]',          \n",
      "                                                                  'activation_59[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_64 (Conv2D)             (None, 3, 3, 192)    147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_64 (BatchN  (None, 3, 3, 192)   576         ['conv2d_64[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_64 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_64[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_65 (Conv2D)             (None, 3, 3, 192)    258048      ['activation_64[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_65 (BatchN  (None, 3, 3, 192)   576         ['conv2d_65[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_65 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_65[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_61 (Conv2D)             (None, 3, 3, 192)    147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_66 (Conv2D)             (None, 3, 3, 192)    258048      ['activation_65[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_61 (BatchN  (None, 3, 3, 192)   576         ['conv2d_61[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_66 (BatchN  (None, 3, 3, 192)   576         ['conv2d_66[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_61 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_61[0][0]'] \n",
      "                                                                                                  \n",
      " activation_66 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_66[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_62 (Conv2D)             (None, 3, 3, 192)    258048      ['activation_61[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_67 (Conv2D)             (None, 3, 3, 192)    258048      ['activation_66[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_62 (BatchN  (None, 3, 3, 192)   576         ['conv2d_62[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_67 (BatchN  (None, 3, 3, 192)   576         ['conv2d_67[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_62 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_62[0][0]'] \n",
      "                                                                                                  \n",
      " activation_67 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_67[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_6 (AveragePo  (None, 3, 3, 768)   0           ['mixed6[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_60 (Conv2D)             (None, 3, 3, 192)    147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_63 (Conv2D)             (None, 3, 3, 192)    258048      ['activation_62[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_68 (Conv2D)             (None, 3, 3, 192)    258048      ['activation_67[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_69 (Conv2D)             (None, 3, 3, 192)    147456      ['average_pooling2d_6[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_60 (BatchN  (None, 3, 3, 192)   576         ['conv2d_60[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_63 (BatchN  (None, 3, 3, 192)   576         ['conv2d_63[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_68 (BatchN  (None, 3, 3, 192)   576         ['conv2d_68[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_69 (BatchN  (None, 3, 3, 192)   576         ['conv2d_69[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_60 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_60[0][0]'] \n",
      "                                                                                                  \n",
      " activation_63 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_63[0][0]'] \n",
      "                                                                                                  \n",
      " activation_68 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_68[0][0]'] \n",
      "                                                                                                  \n",
      " activation_69 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_69[0][0]'] \n",
      "                                                                                                  \n",
      " mixed7 (Concatenate)           (None, 3, 3, 768)    0           ['activation_60[0][0]',          \n",
      "                                                                  'activation_63[0][0]',          \n",
      "                                                                  'activation_68[0][0]',          \n",
      "                                                                  'activation_69[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_72 (Conv2D)             (None, 3, 3, 192)    147456      ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_72 (BatchN  (None, 3, 3, 192)   576         ['conv2d_72[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_72 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_72[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_73 (Conv2D)             (None, 3, 3, 192)    258048      ['activation_72[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_73 (BatchN  (None, 3, 3, 192)   576         ['conv2d_73[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_73 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_73[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_70 (Conv2D)             (None, 3, 3, 192)    147456      ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_74 (Conv2D)             (None, 3, 3, 192)    258048      ['activation_73[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_70 (BatchN  (None, 3, 3, 192)   576         ['conv2d_70[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_74 (BatchN  (None, 3, 3, 192)   576         ['conv2d_74[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_70 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_70[0][0]'] \n",
      "                                                                                                  \n",
      " activation_74 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_74[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_71 (Conv2D)             (None, 1, 1, 320)    552960      ['activation_70[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_75 (Conv2D)             (None, 1, 1, 192)    331776      ['activation_74[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_71 (BatchN  (None, 1, 1, 320)   960         ['conv2d_71[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_75 (BatchN  (None, 1, 1, 192)   576         ['conv2d_75[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_71 (Activation)     (None, 1, 1, 320)    0           ['batch_normalization_71[0][0]'] \n",
      "                                                                                                  \n",
      " activation_75 (Activation)     (None, 1, 1, 192)    0           ['batch_normalization_75[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 1, 1, 768)   0           ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " mixed8 (Concatenate)           (None, 1, 1, 1280)   0           ['activation_71[0][0]',          \n",
      "                                                                  'activation_75[0][0]',          \n",
      "                                                                  'max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_80 (Conv2D)             (None, 1, 1, 448)    573440      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_80 (BatchN  (None, 1, 1, 448)   1344        ['conv2d_80[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_80 (Activation)     (None, 1, 1, 448)    0           ['batch_normalization_80[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_77 (Conv2D)             (None, 1, 1, 384)    491520      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_81 (Conv2D)             (None, 1, 1, 384)    1548288     ['activation_80[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_77 (BatchN  (None, 1, 1, 384)   1152        ['conv2d_77[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_81 (BatchN  (None, 1, 1, 384)   1152        ['conv2d_81[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_77 (Activation)     (None, 1, 1, 384)    0           ['batch_normalization_77[0][0]'] \n",
      "                                                                                                  \n",
      " activation_81 (Activation)     (None, 1, 1, 384)    0           ['batch_normalization_81[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_78 (Conv2D)             (None, 1, 1, 384)    442368      ['activation_77[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_79 (Conv2D)             (None, 1, 1, 384)    442368      ['activation_77[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_82 (Conv2D)             (None, 1, 1, 384)    442368      ['activation_81[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_83 (Conv2D)             (None, 1, 1, 384)    442368      ['activation_81[0][0]']          \n",
      "                                                                                                  \n",
      " average_pooling2d_7 (AveragePo  (None, 1, 1, 1280)  0           ['mixed8[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_76 (Conv2D)             (None, 1, 1, 320)    409600      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_78 (BatchN  (None, 1, 1, 384)   1152        ['conv2d_78[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_79 (BatchN  (None, 1, 1, 384)   1152        ['conv2d_79[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_82 (BatchN  (None, 1, 1, 384)   1152        ['conv2d_82[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_83 (BatchN  (None, 1, 1, 384)   1152        ['conv2d_83[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_84 (Conv2D)             (None, 1, 1, 192)    245760      ['average_pooling2d_7[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_76 (BatchN  (None, 1, 1, 320)   960         ['conv2d_76[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_78 (Activation)     (None, 1, 1, 384)    0           ['batch_normalization_78[0][0]'] \n",
      "                                                                                                  \n",
      " activation_79 (Activation)     (None, 1, 1, 384)    0           ['batch_normalization_79[0][0]'] \n",
      "                                                                                                  \n",
      " activation_82 (Activation)     (None, 1, 1, 384)    0           ['batch_normalization_82[0][0]'] \n",
      "                                                                                                  \n",
      " activation_83 (Activation)     (None, 1, 1, 384)    0           ['batch_normalization_83[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_84 (BatchN  (None, 1, 1, 192)   576         ['conv2d_84[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_76 (Activation)     (None, 1, 1, 320)    0           ['batch_normalization_76[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9_0 (Concatenate)         (None, 1, 1, 768)    0           ['activation_78[0][0]',          \n",
      "                                                                  'activation_79[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 1, 1, 768)    0           ['activation_82[0][0]',          \n",
      "                                                                  'activation_83[0][0]']          \n",
      "                                                                                                  \n",
      " activation_84 (Activation)     (None, 1, 1, 192)    0           ['batch_normalization_84[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9 (Concatenate)           (None, 1, 1, 2048)   0           ['activation_76[0][0]',          \n",
      "                                                                  'mixed9_0[0][0]',               \n",
      "                                                                  'concatenate[0][0]',            \n",
      "                                                                  'activation_84[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_89 (Conv2D)             (None, 1, 1, 448)    917504      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_89 (BatchN  (None, 1, 1, 448)   1344        ['conv2d_89[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_89 (Activation)     (None, 1, 1, 448)    0           ['batch_normalization_89[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_86 (Conv2D)             (None, 1, 1, 384)    786432      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_90 (Conv2D)             (None, 1, 1, 384)    1548288     ['activation_89[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_86 (BatchN  (None, 1, 1, 384)   1152        ['conv2d_86[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_90 (BatchN  (None, 1, 1, 384)   1152        ['conv2d_90[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_86 (Activation)     (None, 1, 1, 384)    0           ['batch_normalization_86[0][0]'] \n",
      "                                                                                                  \n",
      " activation_90 (Activation)     (None, 1, 1, 384)    0           ['batch_normalization_90[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_87 (Conv2D)             (None, 1, 1, 384)    442368      ['activation_86[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_88 (Conv2D)             (None, 1, 1, 384)    442368      ['activation_86[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_91 (Conv2D)             (None, 1, 1, 384)    442368      ['activation_90[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_92 (Conv2D)             (None, 1, 1, 384)    442368      ['activation_90[0][0]']          \n",
      "                                                                                                  \n",
      " average_pooling2d_8 (AveragePo  (None, 1, 1, 2048)  0           ['mixed9[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_85 (Conv2D)             (None, 1, 1, 320)    655360      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_87 (BatchN  (None, 1, 1, 384)   1152        ['conv2d_87[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_88 (BatchN  (None, 1, 1, 384)   1152        ['conv2d_88[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_91 (BatchN  (None, 1, 1, 384)   1152        ['conv2d_91[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_92 (BatchN  (None, 1, 1, 384)   1152        ['conv2d_92[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_93 (Conv2D)             (None, 1, 1, 192)    393216      ['average_pooling2d_8[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_85 (BatchN  (None, 1, 1, 320)   960         ['conv2d_85[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_87 (Activation)     (None, 1, 1, 384)    0           ['batch_normalization_87[0][0]'] \n",
      "                                                                                                  \n",
      " activation_88 (Activation)     (None, 1, 1, 384)    0           ['batch_normalization_88[0][0]'] \n",
      "                                                                                                  \n",
      " activation_91 (Activation)     (None, 1, 1, 384)    0           ['batch_normalization_91[0][0]'] \n",
      "                                                                                                  \n",
      " activation_92 (Activation)     (None, 1, 1, 384)    0           ['batch_normalization_92[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_93 (BatchN  (None, 1, 1, 192)   576         ['conv2d_93[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_85 (Activation)     (None, 1, 1, 320)    0           ['batch_normalization_85[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9_1 (Concatenate)         (None, 1, 1, 768)    0           ['activation_87[0][0]',          \n",
      "                                                                  'activation_88[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 1, 1, 768)    0           ['activation_91[0][0]',          \n",
      "                                                                  'activation_92[0][0]']          \n",
      "                                                                                                  \n",
      " activation_93 (Activation)     (None, 1, 1, 192)    0           ['batch_normalization_93[0][0]'] \n",
      "                                                                                                  \n",
      " mixed10 (Concatenate)          (None, 1, 1, 2048)   0           ['activation_85[0][0]',          \n",
      "                                                                  'mixed9_1[0][0]',               \n",
      "                                                                  'concatenate_1[0][0]',          \n",
      "                                                                  'activation_93[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 21,768,352\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pre_trained_model = InceptionV3(input_shape=(75, 75, 3),\n",
    "                                include_top=False,\n",
    "                                weights=None)\n",
    "pre_trained_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ll30XUe8EQnZ"
   },
   "source": [
    "#### 6. 이제 Inception V3 모델을 어디까지 사용할 것인지 결정해야 한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yCTWgLmcEsaV"
   },
   "source": [
    "모델의 구조를 살펴보고 'mixed7'까지 사용하기로 결정했다고 하자. 그러면 마지막 계층을 얻어온다. 그리고 이 계층의 출력을 펼쳐서 입력으로 하는 레이어를 시작으로 몇 개의 층을 만든다. 이 층들을 케라스의 함수형 모델 API를 이용하여 만들자. 이 함수형 모델은 입력 신호를 생성하는 계층을 새로운 계층에 연결해 만드는데, 최종적으로 우리의 분류 목적에 맞게 10개의 출력을 가지도록 만들었다. 이 계층들을 x 변수에 담았다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UjFjcS6hEsHn"
   },
   "outputs": [],
   "source": [
    "# last_layer  = pre_trained_model.get_layer('mixed7')\n",
    "last_layer  = pre_trained_model.get_layer('mixed10')\n",
    "last_output = last_layer.output\n",
    "\n",
    "x = layers.Flatten()(last_output)\n",
    "# x = layers.Dense(1024, activation='relu')(x)\n",
    "# x = layers.Dense(10, activation='sigmoid')(x)\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "x = layers.Dense(10, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ywsFr_uEtBY"
   },
   "source": [
    "#### 7. 이제 Inception V3 모델의 일부와 새로운 계층들을 연결해 우리의 모델을 만들어야 한다. 이것은 케라스의 Model을 생성하면서 둘을 나열하면 된다. 모델을 만들고 컴파일한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yMMWkxQpE1hW",
    "outputId": "fdb6bcfd-4235-4cf2-9fbe-b4688d89b24c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(RMSprop, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Model(pre_trained_model.input, x)\n",
    "\n",
    "model.compile(optimizer=RMSprop(lr=0.001),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7SOPKnKE2Df"
   },
   "source": [
    "#### 8. 다음으로 에폭을 20으로 하고 모델을 학습시키도록 한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vox1dmFlFT1S"
   },
   "source": [
    "신경망의 층도 많고 학습할 파라미터가 많기 때문에 첫 에폭을 시작하기 전에 매우 오랜 시간이 걸리며, 매 에폭마다 소요되는 학습 시간도 길다. 하지만 참고 기다리면 특징을 잘 찾아내는 합성곱 신경망 모델갑게 훈련 데이터에 대해 99%를 넘는 매우 높은 정확도를 가지는 분류기를 얻을 수 잇다. 데이터의 수를 줄여서 학습을 진행했기 때문에 과적합의 위험이 존재한다. 실제로 학습 중반까지는 검증 데이터에 대한 정확도가 매우 불안정할 수도 잇다. 그러나 학습 후반부에는 상당한 수준으로 높아질 것이다. 데이터 수를 늘려서 학습하면 과적합의 위험을 피할 수 있겠지만 학습에 걸리는 시간이 그 만큼 늘어날 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PJ2vyoqmFTf6"
   },
   "outputs": [],
   "source": [
    "history = model.fit(x_train_preprocess, y_train, epochs=20,\n",
    "                    validation_data=(x_test_preprocess, y_test), verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u9GZuYLLFUZP"
   },
   "source": [
    "#### 9. 훈련 과정에서 모델이 보인 예측 정확도와 손실 값을 확인하기 위해 값들을 얻자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JPpIbrGPFY83"
   },
   "outputs": [],
   "source": [
    "acc     = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss    = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TBG47VYdFZSZ"
   },
   "source": [
    "#### 10. 훈련 과정의 정확도와 손실을 화면에 그려서 확인해 보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mgUQ_D26ZuIY"
   },
   "source": [
    "테스트 데이터에 대해서도 99.4% 수준의 높은 정확도로 예측이 가능한 좋은 모델이 만들어졌다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 580
    },
    "id": "5LXFo8DuFjCt",
    "outputId": "a181091a-0331-4a92-ee13-efca0bfaeaec"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs, acc, 'r', label='Training accuray')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuray')\n",
    "plt.title(\"Mnist Training accuracy\")\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title(\"Mnist Training loss\")\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RmjUshAgFkkv"
   },
   "source": [
    "그런데, 이 실습에서 몇 가지 문제를 발견할 수 있다. 우선은 매우 복잡한 모델이기 때문에 새로 훈련시키는 데에 너무 오랜 시간이 걸린다. 그리고 이미 방대한 양의 데이터로 Inception V3를 학습시켜 놓았는데, 가중치를 난수로 초기화하고 전체를 새로 학습하고 있다. 이것은 이전의 학습을 활용하지 못 하는 것이다. 이러한 문제를 개선하기 위해 **전이학습**<sup>transfer learning</sup>이라는 개념을 사용할 수 있다."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Lab9-3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
